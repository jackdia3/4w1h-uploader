#!/usr/bin/env python3
"""
Batch smartâ€‘cropper
===================

ä½¿ç”¨ç¯„ä¾‹
--------
$ python smart_crop_v2.py /path/to/product_383
# â†’ æ–¼ /path/to/product_383/split ç”¢ç”Ÿè£ç‰‡ï¼Œä¸”å¯«å…¥ process_summary.json

å¯é¸åƒæ•¸ï¼š
  --out   æŒ‡å®šè¼¸å‡ºæ ¹è³‡æ–™å¤¾ï¼ˆé è¨­ç‚º <input>/splitï¼‰
  --ext   é€—è™Ÿåˆ†éš”çš„å‰¯æª”ååˆ—è¡¨ï¼ˆé è¨­ jpg,jpeg,png,webp,bmp,tif,tiffï¼‰

ç¨‹å¼ç‰¹è‰²
--------
* **å…©éšæ®µ cutâ€‘line åµæ¸¬**ï¼š
  1. é€£çºŒç´”ç™½è¡Œ (projection)
  2. é•·åœ– edgeâ€‘projectionï¼ˆåƒ…æ–¼ h > 2,000 æ™‚å•Ÿç”¨ï¼‰
* **å‹•æ…‹é–€æª»** ä¾åœ–ç‰‡å¯¬åº¦è‡ªèª¿ã€‚
* è‡ªå‹•å»é™¤é€£çºŒç´”ç™½é‚Šæ¡† & å°ç¢ç‰‡ã€‚
* è¼¸å‡º JSON summary ä¾›å¾ŒçºŒæµæ°´ç·šä½¿ç”¨ã€‚
"""
from __future__ import annotations

import argparse
import json
import logging
import os
from datetime import datetime
from itertools import chain
from pathlib import Path
from typing import List, Tuple

import cv2
import numpy as np
from PIL import Image

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¸¸æ•¸ åŠ logging
LONG_SIDE_THRESHOLD = 2_000       # h > æ­¤å€¼è¦–ç‚ºé•·åœ–ï¼Œå•Ÿç”¨ edgeâ€‘projection
MIN_CROP_HEIGHT = 120             # è£ç‰‡æœ€å°é«˜åº¦ï¼ˆpxï¼‰
BG_THRESH = 245                   # > æ­¤ç°åº¦è¦–ç‚ºç™½
CONSEC_BORDER = 15                # é‚Šæ¡†æƒæé€£çºŒç™½è¡Œ/åˆ—é–€æª»
MIN_BAND_MEAN = 250              # åˆ¤æ–· 'ç´”ç™½å¸¶' çš„å¹³å‡äº®åº¦é–€æª»
MIN_WHITE_RATIO = 0.92           # è©² band å…§ >245 çš„åƒç´ ä½”æ¯”

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
log = logging.getLogger("smart_crop")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸºæœ¬å·¥å…·

def trim_border(img: np.ndarray, bg_thresh: int = BG_THRESH, consec: int = CONSEC_BORDER) -> Tuple[int, int, int, int]:
    """åµæ¸¬å››å‘¨ç´”ç™½é‚Šæ¡†ï¼Œå›å‚³ (top, bottom, left, right) æ‡‰è£æ‰çš„åƒç´ æ•¸"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape

    def _scan(indices, axis: str):
        run = 0
        for idx in indices:
            line = gray[idx] if axis == "row" else gray[:, idx]
            if (line > bg_thresh).all():
                run += 1
                if run >= consec:
                    continue
            else:
                break
        return run

    top = _scan(range(h), "row")
    bottom = _scan(range(h - 1, -1, -1), "row")
    left = _scan(range(w), "col")
    right = _scan(range(w - 1, -1, -1), "col")
    return top, bottom, left, right


def merge_close(lines: List[int], orig_h: int, ratio: float = 0.06) -> List[int]:
    """åˆä½µå½¼æ­¤è·é›¢éè¿‘çš„ cutâ€‘lines"""
    if not lines:
        return []
    min_gap = max(120, int(ratio * orig_h))
    merged = [lines[0]]
    for y in lines[1:]:
        if y - merged[-1] >= min_gap:
            merged.append(y)
    return merged


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ cutâ€‘line åµæ¸¬

def blank_projection(gray: np.ndarray) -> List[int]:
    """ä¾ç´”ç™½å¸¶åµæ¸¬ cutâ€‘linesï¼ˆå‹•æ…‹é–€æª»ï¼‰"""
    h, w = gray.shape
    if w <= 800:
        min_blank_run = 6
    elif w <= 1600:
        min_blank_run = 8
    else:
        min_blank_run = 10

    # ç®—æ¯åˆ— "çœŸç™½"(>245) çš„æ¯”ä¾‹ & å¹³å‡äº®åº¦
    white_ratio = (gray > BG_THRESH).mean(axis=1)
    row_mean = gray.mean(axis=1)

    blank_mask = (white_ratio > MIN_WHITE_RATIO) & (row_mean > MIN_BAND_MEAN)

    lines, run = [], None
    for y, blank in enumerate(blank_mask):
        if blank and run is None:
            run = y
        elif not blank and run is not None:
            if y - run >= min_blank_run:
                lines.append((run + y - 1) // 2)
            run = None
    if run is not None and h - run >= min_blank_run:
        lines.append((run + h - 1) // 2)
    return lines


def long_edge_projection(gray: np.ndarray) -> List[int]:
    """é•·åœ–æ‰å•Ÿç”¨ï¼šæ‰¾é‚Šç·£ç¨€ç–å¸¶"""
    h, w = gray.shape
    if h <= LONG_SIDE_THRESHOLD:
        return []
    edges = cv2.Canny(gray, 50, 150)
    profile = edges.sum(axis=1) / w
    low = profile < 0.05 * 255
    kernel = np.ones((40, 1), np.uint8)
    band = cv2.morphologyEx(low.astype(np.uint8)[:, None], cv2.MORPH_CLOSE, kernel)[:, 0]

    lines = []
    start = None
    for y, val in enumerate(band):
        if val and start is None:
            start = y
        elif not val and start is not None:
            if 0.1 * h < (mid := (start + y) // 2) < 0.9 * h:
                lines.append(mid)
            start = None
    return lines


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¿ç•™/æ¨æ£„é‚è¼¯

def small_fragment(h_seg: int, width: int, orig_h: int, is_text: bool = False) -> bool:
    """åˆ¤æ–·ç‰‡æ®µæ˜¯å¦éå°å¯ä¸Ÿæ£„"""
    min_keep = max(int(0.08 * orig_h), int(0.25 * width), MIN_CROP_HEIGHT)
    return (h_seg < min_keep) and (not is_text)


def looks_like_text(seg: np.ndarray) -> bool:
    gray = cv2.cvtColor(seg, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    ratio = edges.sum() / edges.size
    return ratio > 0.05 and gray.std() < 15


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸»è£åˆ‡

def crop_image(img: np.ndarray, image_path: Path, out_root: Path) -> List[dict]:
    h, w = img.shape[:2]
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    lines = merge_close(sorted(set(blank_projection(gray) + long_edge_projection(gray))), h)
    # è‹¥ç„¡åˆ‡é» â†’ ä¸è£ä½†ä»è¼¸å‡º 1 å¼µ
    lines = [0] + lines + [h]

    # è™•ç†ç›¸å°è·¯å¾‘
    try:
        rel_dir = image_path.parent.relative_to(out_root.parent)
    except ValueError:
        # out_root ä¸åœ¨ input_dir è£¡ â†’ åªç”¨æœ€å¾Œä¸€å±¤è³‡æ–™å¤¾å
        rel_dir = Path(image_path.parent.name)
    out_dir = out_root / rel_dir
    out_dir.mkdir(parents=True, exist_ok=True)

    crops = []
    crop_idx = 0  # é€£çºŒç·¨è™Ÿè¨ˆæ•¸å™¨
    for idx in range(len(lines) - 1):
        y1, y2 = lines[idx], lines[idx + 1]
        seg_h = y2 - y1
        seg = img[y1:y2]
        if small_fragment(seg_h, w, h, looks_like_text(seg)):
            continue
            
        dst = out_dir / f"{image_path.stem}_crop_{crop_idx}.webp"
        cv2.imwrite(str(dst), seg)
        crops.append(
            {
                "path": str(dst),
                "height": seg_h,
                "width": w,
                "y_start": y1,
                "y_end": y2,
            }
        )
        crop_idx += 1  # åªæœ‰æˆåŠŸå„²å­˜æ‰å¢åŠ ç·¨è™Ÿ
    return crops


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ‰¹æ¬¡è™•ç†

def process_dir(input_dir: Path, out_root: Path, exts: Tuple[str, ...]):
    summary = {
        "input_dir": str(input_dir),
        "output_dir": str(out_root),
        "start": datetime.now().isoformat(),
        "total_images": 0,
        "total_crops": 0,
        "files": {},
    }
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºå–®ä¸€æª”æ¡ˆ
    if input_dir.is_file():
        paths = [input_dir]
    else:
        paths = sorted(p for p in input_dir.rglob("*") 
                      if p.suffix.lower().lstrip(".") in exts)
    
    for path in paths:
        try:
            img = cv2.imread(str(path))
            if img is None:
                log.warning(f"âš ï¸  ç„¡æ³•è®€å– {path}")
                continue
                
            # å»é‚Š
            t, b, l, r = trim_border(img)
            if any((t, b, l, r)):
                img = img[t : img.shape[0] - b, l : img.shape[1] - r]
                
            crops = crop_image(img, path, out_root)
            summary["total_images"] += 1
            summary["total_crops"] += len(crops)
            summary["files"][str(path)] = crops
            
        except Exception as e:
            log.error(f"è™•ç† {path} å¤±æ•—: {e}")
            
    summary["end"] = datetime.now().isoformat()
    with open(out_root / "process_summary.json", "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    log.info(f"âœ… å®Œæˆï¼å…±è™•ç† {summary['total_images']} å¼µï¼Œè¼¸å‡º {summary['total_crops']} å€‹è£ç‰‡")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI

def parse_args():
    p = argparse.ArgumentParser(description="Smart batch cropper")
    p.add_argument("input", type=Path, help="è¦è™•ç†çš„ç›®éŒ„")
    p.add_argument("--out", type=Path, default=None, help="è¼¸å‡ºæ ¹è³‡æ–™å¤¾ (é è¨­ <input>/split)")
    p.add_argument(
        "--ext",
        default="jpg,jpeg,png,webp,bmp,tif,tiff",
        help="è¦è™•ç†çš„å‰¯æª”å (é€—è™Ÿåˆ†éš”)"
    )
    return p.parse_args()


def main():
    args = parse_args()
    input_dir: Path = args.input.resolve()
    out_root: Path = (args.out or (input_dir / "split")).resolve()
    out_root.mkdir(parents=True, exist_ok=True)

    exts = tuple(e.lower() for e in args.ext.split(','))
    log.info(f"ğŸ“‚ ä¾†æº: {input_dir}")
    log.info(f"ğŸ“¦ è¼¸å‡º: {out_root}")
    log.info(f"ğŸ” å‰¯æª”å: {exts}")
    process_dir(input_dir, out_root, exts)


if __name__ == "__main__":
    main()
